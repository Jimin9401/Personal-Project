{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.metrics import f1_score,confusion_matrix,accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../pickle_data/charlevel.pickle\", \"rb\") as f:\n",
    "    balenced_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['char_chat', 'idx2char', 'char2idx', 'target'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balenced_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = balenced_data[\"char_chat\"]\n",
    "target = balenced_data[\"target\"]\n",
    "char2idx = balenced_data[\"char2idx\"]\n",
    "idx2char= balenced_data[\"idx2char\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i,k in zip(comment,target):\n",
    "    a.append([i,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45427"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45427"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(token):\n",
    "    token_post=token.copy()\n",
    "    len_sentence=[ len(i) for i in token_post]\n",
    "    max_sentence=max(len_sentence) #최대 문장길이 9591\n",
    "    n=-1\n",
    "    for i in token_post:\n",
    "        n+=1\n",
    "        k=len(token_post[n])\n",
    "        while max_sentence-k>=0:\n",
    "            token_post[n].append('<pad>')\n",
    "            k+=1\n",
    "    return token_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=list(map(lambda x: padding(x),  [comment]))\n",
    "comment=comment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "li1=[]\n",
    "comment_list=[]\n",
    "for i in comment:\n",
    "    for k in i:\n",
    "        li1.append(char2idx[k])\n",
    "    \n",
    "    comment_list.append(li1)\n",
    "    li1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(comment_list,target,test_size=0.26,random_state=7,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33615"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec=Word2Vec.load('../word2vec_model/char_model_200.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962\n",
      "1962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "embedding_matrix = []\n",
    "\n",
    "for word in char2idx.keys():\n",
    "    try:\n",
    "        embedding_matrix.append(model_word2vec[word])\n",
    "    except:\n",
    "        embedding_matrix.append(np.zeros(200))\n",
    "\n",
    "print(len(char2idx))\n",
    "print(len(embedding_matrix))\n",
    "\n",
    "embedding_matrix = torch.Tensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.FloatTensor(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Clf(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size,num_class,num_layers,hidden_size,bidirectional,num_directions):\n",
    "        \n",
    "        super(LSTM_Clf,self).__init__()\n",
    "        \n",
    "        # 안에 하이퍼 파라미터의 종류들 선언\n",
    "        \n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_size=hidden_size\n",
    "        self.input_size=input_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.num_class=num_class\n",
    "        self.num_directions=num_directions\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings=embedding_matrix)\n",
    "                                    \n",
    "   #     self.normal=torch.normal()\n",
    "        self.lstm=nn.LSTM(input_size=embedding_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        num_layers=num_layers,\n",
    "                        batch_first=True,\n",
    "                        bidirectional=bidirectional) # 해당 sequence의 앞 뒤를 모두 고려해서 반영\n",
    "        \n",
    "        self.linear=nn.Linear(in_features=hidden_size*num_directions,out_features=num_class)\n",
    "        \n",
    "    #    self.out=nn.Linear(num_class,1)\n",
    "\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        hidden,cell=self.init_hidden(batch_size)\n",
    "        \n",
    "        embed=self.embedding(inputs)\n",
    "        \n",
    "    #    embed=self.normal(embed)\n",
    "        \n",
    "        out, _ =self.lstm(embed,(hidden,cell))\n",
    "        \n",
    "        out=self.linear(out[:, -1:, :].squeeze(1))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def predict(self,inputs):\n",
    "        \n",
    "        hidden,cell = self.init_hidden(1)\n",
    "        embed = self.embedding(inputs)\n",
    "    #    embed=self.normal(embed)\n",
    "        # Propagate embedding through RNN\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # hidden: (num_layers * num_directions, batch, hidden_size)\n",
    "        \n",
    "        out, _ = self.lstm(embed, (hidden,cell))\n",
    "        \n",
    "        return self.linear(out[:, -1:, :]).squeeze(1)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        hidden=Variable(torch.zeros(self.num_layers*self.num_directions,batch_size, self.hidden_size)).to(device)\n",
    "        cell=Variable(torch.zeros(self.num_layers*self.num_directions,batch_size, self.hidden_size)).to(device)\n",
    "        \n",
    "        return hidden,cell\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=Dataset(np.array(X_train),y_train)\n",
    "test_data=Dataset(np.array(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_data,batch_size=27*5,shuffle=True)\n",
    "test_loader=DataLoader(test_data,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=27*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Clf(input_size=len(char2idx),num_directions=2, embedding_size = 200,hidden_size=len(X_train[0]),\n",
    "                num_layers=3,num_class=2,bidirectional=True).to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.003,weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [1/50] Step [30/249], Loss: 0.5309\n",
      "epoch: [1/50] Step [60/249], Loss: 0.5389\n",
      "epoch: [1/50] Step [89/249], Loss: 0.5035\n",
      "epoch: [1/50] Step [90/249], Loss: 0.6284\n",
      "epoch: [1/50] Step [120/249], Loss: 0.4918\n",
      "epoch: [1/50] Step [150/249], Loss: 0.5976\n",
      "epoch: [1/50] Step [180/249], Loss: 0.5676\n",
      "epoch: [1/50] Step [210/249], Loss: 0.5528\n",
      "epoch: [1/50] Step [240/249], Loss: 0.5878\n",
      "\n",
      "\n",
      "=====update finished!=====\n",
      "test_acc: 0.777\n",
      "test_f1_score: 0.000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-30de1831d6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EPOCH=50\n",
    "batch_size=27*5\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    test_pred=[]\n",
    "    test_true=[]\n",
    "    train_loader=DataLoader(train_data,batch_size=27*5,shuffle=True)\n",
    "    test_loader=DataLoader(test_data,batch_size=1,shuffle=False)\n",
    "    \n",
    "    for k,(X_batch,y_batch) in enumerate(train_loader):\n",
    "        inputs=Variable(torch.LongTensor(X_batch)).to(device)\n",
    "        targets=Variable(torch.LongTensor(y_batch)).to(device)\n",
    "        \n",
    "        y_pred=model(inputs)\n",
    "        \n",
    "        loss=loss_function(y_pred,targets)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (k+1) % 30==0 or k+1==89:\n",
    "            print('epoch: [{}/{}] Step [{}/{}], Loss: {:.4f}'\n",
    "                .format((epoch+1),EPOCH,(k+1),len(train_loader),loss))\n",
    "    print('\\n')        \n",
    "    print('=====update finished!=====')\n",
    "    \n",
    "    for k,(X_batch,y_batch) in enumerate(test_loader):\n",
    "        inputs=Variable(torch.LongTensor(X_batch)).to(device)\n",
    "        targets=Variable(torch.LongTensor(y_batch)).to(device)\n",
    "        \n",
    "        y_pred=model.predict(inputs)\n",
    "        y_pred=torch.max(y_pred,1)[1].item()\n",
    "        \n",
    "        test_pred.append(y_pred)\n",
    "        test_true.append(targets.item())\n",
    "        \n",
    "    print('test_acc: %.3f' %(accuracy_score(y_true=test_true,y_pred=test_pred)))\n",
    "    print('test_f1_score: %.3f' %(f1_score(y_true=test_true,y_pred=test_pred)))\n",
    "    print('\\n') \n",
    "        \n",
    "\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
