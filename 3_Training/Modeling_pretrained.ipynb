{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.metrics import f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./pickle/token_data.pickle\", \"rb\") as f:\n",
    "    token_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = token_data[\"comment\"]\n",
    "target = token_data[\"target\"]\n",
    "reviews_idx = token_data[\"comment_ix\"]\n",
    "word2idx = token_data[\"word2ix\"]\n",
    "idx2word = token_data[\"ix2word\"]\n",
    "max_seq_length = token_data[\"max_seq_length\"]\n",
    "idx2target={1:'highlight',0:'no'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(token):\n",
    "    token_post=token.copy()\n",
    "    len_sentence=[ len(i) for i in token_post]\n",
    "    max_sentence=max(len_sentence) #최대 문장길이 9591\n",
    "    n=-1\n",
    "    for i in token_post:\n",
    "        n+=1\n",
    "        k=len(token_post[n])\n",
    "        while max_sentence-k>=0:\n",
    "            token_post[n].append('<PAD>')\n",
    "            k+=1\n",
    "    return token_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=list(map(lambda x: padding(x),  [comment]))\n",
    "comment=comment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "li1=[]\n",
    "comment_list=[]\n",
    "for i in comment:\n",
    "    for k in i:\n",
    "        li1.append(word2idx[k])\n",
    "    \n",
    "    comment_list.append(li1)\n",
    "    li1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(comment_list,target,test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmi\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load('word2vec_50_ver2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17786\n",
      "17786\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "embedding_matrix = []\n",
    "\n",
    "for word in word2idx.keys():\n",
    "    try:\n",
    "        embedding_matrix.append(model[word])\n",
    "    except:\n",
    "        embedding_matrix.append(np.zeros(50))\n",
    "\n",
    "print(len(word2idx))\n",
    "print(len(embedding_matrix))\n",
    "\n",
    "embedding_matrix = torch.Tensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.9961,  0.4729,  0.2791,  ...,  0.2730, -1.1971,  0.1223],\n",
       "        ...,\n",
       "        [-0.0096,  0.0076, -0.0067,  ..., -0.0008, -0.0002,  0.0026],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0720,  0.5453, -0.8303,  ..., -0.7007, -0.9369, -0.6074]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoW_Clf_Embed_mean(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, output_size, embedding_matrix):\n",
    "        super(BoW_Clf_Embed_mean, self).__init__()\n",
    "#         self.embed = nn.Embedding.from_pretrained(embedding_matrix, freeze=False) # True is Default\n",
    "        self.embed = nn.Embedding.from_pretrained(embedding_matrix,freeze=False)\n",
    "        \n",
    "        self.rnn=nn.RNN(batch_first=True,)\n",
    "        \n",
    "        self.linear = nn.Linear(embedding_size, output_size)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        embed = self.embed(inputs)\n",
    "        embed_mean = torch.mean(embed, 1)\n",
    "        return self.linear(embed_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6809141039848328\n",
      "0.5512250661849976\n",
      "0.5296952128410339\n",
      "0.5332592725753784\n",
      "0.5291300415992737\n",
      "0.528171181678772\n",
      "0.5281693339347839\n",
      "0.5278354287147522\n",
      "0.5276939272880554\n",
      "0.527576744556427\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "\n",
    "model = BoW_Clf_Embed_mean(len(word2idx),50, 2, embedding_matrix).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=LR, momentum=0.9)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    model.zero_grad()\n",
    "    inputs = Variable(torch.LongTensor(X_train)).to(device)\n",
    "    targets = Variable(torch.LongTensor(y_train)).to(device)\n",
    "    \n",
    "    preds = model(inputs)\n",
    "    \n",
    "    loss = loss_function(preds, targets)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : ['킹/Noun', '리/Noun', '아/Exclamation', '나/Noun']\n",
      "Prediction : 0\n",
      "Truth : 0\n",
      "\n",
      "\n",
      "Input : ['쉔무/Noun', '새/Noun']\n",
      "Prediction : 0\n",
      "Truth : 0\n",
      "\n",
      "\n",
      "Accuracy :77.55161809928246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:0.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "list_predicted=[]\n",
    "model.eval()\n",
    "for i, seq in enumerate(X_test):\n",
    "    input = Variable(torch.LongTensor(seq).view(1,-1)).to(device)\n",
    "    pred = model(input)\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    list_predicted.append(pred)\n",
    "    true = y_test[i]\n",
    "    if true == pred.item():\n",
    "        correct +=1\n",
    "    \n",
    "    if i%10000 == 0:\n",
    "        input_seq = [idx2word.get(ix) for ix in seq if ix != 0]\n",
    "        print(\"Input :\", input_seq)\n",
    "        print(\"Prediction :\", pred.item())\n",
    "        print(\"Truth :\", y_test[i])\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"Accuracy :%s\" %(correct/len(X_test)*100))\n",
    "print('F1 score:%s' %(f1_score(list_predicted,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10592  3066]\n",
      " [    0     0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(list_predicted,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
